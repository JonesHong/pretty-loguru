#!/usr/bin/env python3
"""
Performance Monitoring - æ€§èƒ½ç›£æ§å’Œå„ªåŒ–

é€™å€‹ç¯„ä¾‹å±•ç¤ºï¼š
1. æ€§èƒ½æŒ‡æ¨™æ”¶é›†å’Œè¨˜éŒ„
2. æ‡‰ç”¨æ€§èƒ½ç›£æ§ (APM)
3. è³‡æºä½¿ç”¨æƒ…æ³è¿½è¹¤
4. æ€§èƒ½ç“¶é ¸è­˜åˆ¥

é‹è¡Œæ–¹å¼ï¼š
    python performance_monitoring.py
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).resolve().parent.parent.parent))

from pretty_loguru import create_logger
import time
import psutil
import threading
from datetime import datetime, timedelta
import random

def system_performance_monitor():
    """ç³»çµ±æ€§èƒ½ç›£æ§"""
    print("=== ç³»çµ±æ€§èƒ½ç›£æ§ ===\n")
    
    logger = create_logger("system_monitor", 
                          log_path="./logs/performance", 
                          preset="hourly",
                          retention="7 days")
    
    logger.ascii_header("SYSTEM PERF", font="slant", border_style="blue")
    
    logger.console_info("ğŸ“Š é–‹å§‹ç³»çµ±æ€§èƒ½ç›£æ§...")
    
    # æ”¶é›†ç³»çµ±æŒ‡æ¨™
    def collect_system_metrics():
        try:
            # CPU ä½¿ç”¨ç‡
            cpu_percent = psutil.cpu_percent(interval=1)
            
            # è¨˜æ†¶é«”ä½¿ç”¨æƒ…æ³
            memory = psutil.virtual_memory()
            memory_percent = memory.percent
            memory_used_gb = memory.used / (1024**3)
            memory_total_gb = memory.total / (1024**3)
            
            # ç£ç¢Ÿä½¿ç”¨æƒ…æ³
            disk = psutil.disk_usage('/')
            disk_percent = (disk.used / disk.total) * 100
            disk_free_gb = disk.free / (1024**3)
            
            # ç¶²è·¯ I/O (å¦‚æœå¯ç”¨)
            try:
                network = psutil.net_io_counters()
                network_sent_mb = network.bytes_sent / (1024**2)
                network_recv_mb = network.bytes_recv / (1024**2)
            except:
                network_sent_mb = network_recv_mb = 0
            
            return {
                'cpu_percent': cpu_percent,
                'memory_percent': memory_percent,
                'memory_used_gb': memory_used_gb,
                'memory_total_gb': memory_total_gb,
                'disk_percent': disk_percent,
                'disk_free_gb': disk_free_gb,
                'network_sent_mb': network_sent_mb,
                'network_recv_mb': network_recv_mb
            }
        except Exception as e:
            # å¦‚æœç„¡æ³•ç²å–çœŸå¯¦æŒ‡æ¨™ï¼Œè¿”å›æ¨¡æ“¬æ•¸æ“š
            logger.warning(f"ç„¡æ³•ç²å–ç³»çµ±æŒ‡æ¨™ï¼Œä½¿ç”¨æ¨¡æ“¬æ•¸æ“š: {e}")
            return {
                'cpu_percent': random.uniform(20, 80),
                'memory_percent': random.uniform(40, 85),
                'memory_used_gb': random.uniform(2, 8),
                'memory_total_gb': 16,
                'disk_percent': random.uniform(30, 70),
                'disk_free_gb': random.uniform(50, 200),
                'network_sent_mb': random.uniform(100, 1000),
                'network_recv_mb': random.uniform(80, 800)
            }
    
    # ç›£æ§é€±æœŸ
    monitoring_cycles = 5
    metrics_history = []
    
    for cycle in range(monitoring_cycles):
        logger.console_info(f"ğŸ“ˆ æ”¶é›†ç¬¬ {cycle + 1} è¼ªæŒ‡æ¨™...")
        
        metrics = collect_system_metrics()
        metrics['timestamp'] = datetime.now().isoformat()
        metrics_history.append(metrics)
        
        # è¨˜éŒ„ç³»çµ±æŒ‡æ¨™
        logger.info(f"ç³»çµ±æŒ‡æ¨™ - CPU: {metrics['cpu_percent']:.1f}%, "
                   f"è¨˜æ†¶é«”: {metrics['memory_percent']:.1f}%, "
                   f"ç£ç¢Ÿ: {metrics['disk_percent']:.1f}%")
        
        # æª¢æŸ¥æ˜¯å¦æœ‰æ€§èƒ½å•é¡Œ
        performance_issues = []
        
        if metrics['cpu_percent'] > 80:
            performance_issues.append(f"CPU ä½¿ç”¨ç‡éé«˜: {metrics['cpu_percent']:.1f}%")
            logger.warning(f"âš ï¸ CPU ä½¿ç”¨ç‡éé«˜: {metrics['cpu_percent']:.1f}%")
        
        if metrics['memory_percent'] > 85:
            performance_issues.append(f"è¨˜æ†¶é«”ä½¿ç”¨ç‡éé«˜: {metrics['memory_percent']:.1f}%")
            logger.warning(f"âš ï¸ è¨˜æ†¶é«”ä½¿ç”¨ç‡éé«˜: {metrics['memory_percent']:.1f}%")
        
        if metrics['disk_percent'] > 90:
            performance_issues.append(f"ç£ç¢Ÿä½¿ç”¨ç‡éé«˜: {metrics['disk_percent']:.1f}%")
            logger.error(f"ğŸš¨ ç£ç¢Ÿä½¿ç”¨ç‡éé«˜: {metrics['disk_percent']:.1f}%")
        
        if not performance_issues:
            logger.debug("âœ“ ç³»çµ±æ€§èƒ½æ­£å¸¸")
        
        time.sleep(2)  # ç­‰å¾…ä¸‹ä¸€è¼ªç›£æ§
    
    # æ€§èƒ½ç¸½çµ
    avg_cpu = sum(m['cpu_percent'] for m in metrics_history) / len(metrics_history)
    avg_memory = sum(m['memory_percent'] for m in metrics_history) / len(metrics_history)
    max_cpu = max(m['cpu_percent'] for m in metrics_history)
    max_memory = max(m['memory_percent'] for m in metrics_history)
    
    performance_summary = [
        f"ç›£æ§é€±æœŸ: {monitoring_cycles} è¼ª",
        f"å¹³å‡ CPU: {avg_cpu:.1f}%",
        f"å¹³å‡è¨˜æ†¶é«”: {avg_memory:.1f}%", 
        f"æœ€é«˜ CPU: {max_cpu:.1f}%",
        f"æœ€é«˜è¨˜æ†¶é«”: {max_memory:.1f}%"
    ]
    
    logger.block("ğŸ“Š æ€§èƒ½ç›£æ§ç¸½çµ", performance_summary, border_style="blue")
    
    return metrics_history

def application_performance_monitor():
    """æ‡‰ç”¨æ€§èƒ½ç›£æ§ (APM)"""
    print("\n=== æ‡‰ç”¨æ€§èƒ½ç›£æ§ ===\n")
    
    logger = create_logger("apm_monitor",
                          log_path="./logs/performance",
                          preset="daily",
                          retention="30 days")
    
    logger.ascii_header("APM", font="slant", border_style="green")
    
    # æ¨¡æ“¬ä¸åŒé¡å‹çš„æ‡‰ç”¨æ“ä½œ
    operations = [
        {"name": "database_query", "avg_time": 45, "variance": 20},
        {"name": "api_request", "avg_time": 180, "variance": 50},
        {"name": "cache_lookup", "avg_time": 5, "variance": 2},
        {"name": "file_upload", "avg_time": 1200, "variance": 300},
        {"name": "data_processing", "avg_time": 800, "variance": 200}
    ]
    
    performance_data = []
    
    logger.console_info("ğŸ” ç›£æ§æ‡‰ç”¨æ€§èƒ½...")
    
    for operation in operations:
        logger.console_info(f"ğŸ“ æ¸¬è©¦æ“ä½œ: {operation['name']}")
        
        # æ¨¡æ“¬å¤šæ¬¡æ“ä½œ
        times = []
        for i in range(10):
            # æ¨¡æ“¬æ“ä½œåŸ·è¡Œæ™‚é–“
            execution_time = max(1, random.gauss(operation['avg_time'], operation['variance'}))
            times.append(execution_time)
            
            # è¨˜éŒ„å–®æ¬¡æ“ä½œ
            logger.debug(f"{operation['name']} åŸ·è¡Œæ™‚é–“: {execution_time:.1f}ms")
            
            # æ¨¡æ“¬æ“ä½œé–“éš”
            time.sleep(0.1)
        
        # è¨ˆç®—çµ±è¨ˆæ•¸æ“š
        avg_time = sum(times) / len(times)
        min_time = min(times)
        max_time = max(times)
        
        # åˆ¤æ–·æ€§èƒ½ç‹€æ³
        if avg_time > operation['avg_time'] * 1.5:
            status = "æ…¢"
            log_level = "warning"
        elif avg_time > operation['avg_time'] * 1.2:
            status = "åæ…¢"
            log_level = "info"
        else:
            status = "æ­£å¸¸"
            log_level = "debug"
        
        # è¨˜éŒ„æ€§èƒ½çµæœ
        perf_msg = (f"{operation['name']} æ€§èƒ½ - "
                   f"å¹³å‡: {avg_time:.1f}ms, "
                   f"æœ€å°: {min_time:.1f}ms, "
                   f"æœ€å¤§: {max_time:.1f}ms, "
                   f"ç‹€æ…‹: {status}")
        
        if log_level == "warning":
            logger.warning(f"âš ï¸ {perf_msg}")
        elif log_level == "info":
            logger.info(f"â„¹ï¸ {perf_msg}")
        else:
            logger.debug(f"âœ“ {perf_msg}")
        
        performance_data.append({
            operation['name'],
            f"{avg_time:.1f}ms", 
            f"{min_time:.1f}ms",
            f"{max_time:.1f}ms",
            status
        })
    
    # æ€§èƒ½æ‘˜è¦è¡¨æ ¼
    logger.table(
        title="âš¡ æ‡‰ç”¨æ€§èƒ½æ‘˜è¦",
        data=performance_data
    )

def database_performance_monitor():
    """è³‡æ–™åº«æ€§èƒ½ç›£æ§"""
    print("\n=== è³‡æ–™åº«æ€§èƒ½ç›£æ§ ===\n")
    
    logger = create_logger("db_monitor",
                          log_path="./logs/performance",
                          rotation="20 MB",
                          retention="14 days")
    
    logger.ascii_header("DATABASE", font="slant", border_style="yellow")
    
    # æ¨¡æ“¬è³‡æ–™åº«æ“ä½œ
    db_operations = [
        {"type": "SELECT", "table": "users", "rows": 1247},
        {"type": "INSERT", "table": "orders", "rows": 1},
        {"type": "UPDATE", "table": "products", "rows": 5},
        {"type": "DELETE", "table": "logs", "rows": 1500},
        {"type": "JOIN", "table": "users_orders", "rows": 856}
    ]
    
    logger.console_info("ğŸ—„ï¸ ç›£æ§è³‡æ–™åº«æ€§èƒ½...")
    
    db_performance_data = []
    total_queries = 0
    slow_queries = 0
    
    for operation in db_operations:
        # æ¨¡æ“¬æŸ¥è©¢åŸ·è¡Œ
        query_time = random.uniform(10, 300)  # 10-300ms
        
        # æ¨¡æ“¬é€£æ¥æ± ç‹€æ…‹
        active_connections = random.randint(5, 50)
        
        # åˆ¤æ–·æ˜¯å¦ç‚ºæ…¢æŸ¥è©¢ (>100ms)
        is_slow = query_time > 100
        if is_slow:
            slow_queries += 1
        
        total_queries += 1
        
        # è¨˜éŒ„æŸ¥è©¢
        query_msg = (f"SQL {operation['type']} - "
                    f"è¡¨: {operation['table']}, "
                    f"å½±éŸ¿è¡Œæ•¸: {operation['rows']}, "
                    f"åŸ·è¡Œæ™‚é–“: {query_time:.1f}ms, "
                    f"é€£æ¥æ•¸: {active_connections}")
        
        if is_slow:
            logger.warning(f"ğŸŒ æ…¢æŸ¥è©¢: {query_msg}")
        else:
            logger.debug(f"âš¡ å¿«æŸ¥è©¢: {query_msg}")
        
        # è¨˜éŒ„é€£æ¥æ± ç‹€æ…‹
        if active_connections > 40:
            logger.warning(f"âš ï¸ é€£æ¥æ± ä½¿ç”¨ç‡é«˜: {active_connections}/50")
        
        db_performance_data.append({
            operation['type'],
            operation['table'],
            str(operation['rows'}),
            f"{query_time:.1f}ms",
            "æ…¢" if is_slow else "å¿«"
        })
        
        time.sleep(0.2)
    
    # è³‡æ–™åº«æ€§èƒ½æ‘˜è¦
    logger.table(
        title="ğŸ—„ï¸ è³‡æ–™åº«æ€§èƒ½æ‘˜è¦", 
        data=db_performance_data
    )
    
    # è³‡æ–™åº«çµ±è¨ˆ
    slow_query_rate = (slow_queries / total_queries) * 100
    
    db_stats = [
        f"ç¸½æŸ¥è©¢æ•¸: {total_queries}",
        f"æ…¢æŸ¥è©¢æ•¸: {slow_queries}",
        f"æ…¢æŸ¥è©¢ç‡: {slow_query_rate:.1f}%",
        f"å¹³å‡é€£æ¥æ•¸: {random.randint(15, 35)}"
    ]
    
    logger.block("ğŸ“ˆ è³‡æ–™åº«çµ±è¨ˆ", db_stats, border_style="yellow")
    
    if slow_query_rate > 20:
        logger.error(f"ğŸš¨ æ…¢æŸ¥è©¢ç‡éé«˜: {slow_query_rate:.1f}%")
    elif slow_query_rate > 10:
        logger.warning(f"âš ï¸ æ…¢æŸ¥è©¢ç‡åé«˜: {slow_query_rate:.1f}%")

def real_time_monitoring():
    """å¯¦æ™‚ç›£æ§æ¨¡æ“¬"""
    print("\n=== å¯¦æ™‚ç›£æ§ ===\n")
    
    logger = create_logger("realtime_monitor",
                          log_path="./logs/performance",
                          preset="minute",
                          retention="24 hours")
    
    logger.ascii_header("REALTIME", font="slant", border_style="magenta")
    
    logger.console_info("ğŸ”´ å•Ÿå‹•å¯¦æ™‚ç›£æ§ (é‹è¡Œ 10 ç§’)...")
    
    # ç›£æ§æŒ‡æ¨™
    metrics = {
        'requests_per_second': 0,
        'response_time': 0,
        'error_rate': 0,
        'active_users': 0
    }
    
    start_time = time.time()
    monitor_duration = 10  # ç›£æ§ 10 ç§’
    
    try:
        while time.time() - start_time < monitor_duration:
            # æ¨¡æ“¬å¯¦æ™‚æŒ‡æ¨™
            metrics['requests_per_second'] = random.randint(50, 200)
            metrics['response_time'] = random.uniform(80, 250)
            metrics['error_rate'] = random.uniform(0, 5)
            metrics['active_users'] = random.randint(100, 500)
            
            # è¨˜éŒ„å¯¦æ™‚æŒ‡æ¨™
            logger.info(f"å¯¦æ™‚æŒ‡æ¨™ - "
                       f"RPS: {metrics['requests_per_second']}, "
                       f"éŸ¿æ‡‰æ™‚é–“: {metrics['response_time']:.1f}ms, "
                       f"éŒ¯èª¤ç‡: {metrics['error_rate']:.2f}%, "
                       f"æ´»èºç”¨æˆ¶: {metrics['active_users']}")
            
            # æª¢æŸ¥ç•°å¸¸æŒ‡æ¨™
            alerts = []
            
            if metrics['response_time'] > 200:
                alerts.append(f"éŸ¿æ‡‰æ™‚é–“éé•·: {metrics['response_time']:.1f}ms")
                
            if metrics['error_rate'] > 3:
                alerts.append(f"éŒ¯èª¤ç‡éé«˜: {metrics['error_rate']:.2f}%")
                
            if metrics['requests_per_second'] > 180:
                alerts.append(f"è«‹æ±‚é‡æ¿€å¢: {metrics['requests_per_second']} RPS")
            
            # è¨˜éŒ„å‘Šè­¦
            for alert in alerts:
                logger.warning(f"âš ï¸ å‘Šè­¦: {alert}")
            
            if not alerts:
                logger.debug("âœ“ æ‰€æœ‰æŒ‡æ¨™æ­£å¸¸")
            
            time.sleep(1)  # æ¯ç§’ç›£æ§ä¸€æ¬¡
    
    except KeyboardInterrupt:
        logger.info("å¯¦æ™‚ç›£æ§è¢«ç”¨æˆ¶ä¸­æ–·")
    
    logger.success("ğŸ”´ å¯¦æ™‚ç›£æ§çµæŸ")

def performance_optimization_tips():
    """æ€§èƒ½å„ªåŒ–å»ºè­°"""
    print("\n=== æ€§èƒ½å„ªåŒ–å»ºè­° ===\n")
    
    logger = create_logger("optimization_tips", log_path="./logs/performance")
    
    logger.ascii_header("OPTIMIZE", font="slant", border_style="cyan")
    
    # åˆ†é¡å„ªåŒ–å»ºè­°
    optimization_categories = {
        "ç³»çµ±å±¤é¢": [
            "ç›£æ§ CPU å’Œè¨˜æ†¶é«”ä½¿ç”¨ç‡ï¼Œé¿å…è³‡æºç“¶é ¸",
            "ä½¿ç”¨ SSD ç¡¬ç¢Ÿæå‡ I/O æ€§èƒ½",
            "é©ç•¶èª¿æ•´ç³»çµ±æ ¸å¿ƒåƒæ•¸",
            "å®šæœŸæ¸…ç†æ—¥èªŒå’Œè‡¨æ™‚æª”æ¡ˆ"
        ],
        "æ‡‰ç”¨å±¤é¢": [
            "å¯¦æ–½æ‡‰ç”¨æ€§èƒ½ç›£æ§ (APM)",
            "è­˜åˆ¥å’Œå„ªåŒ–æ…¢æŸ¥è©¢",
            "ä½¿ç”¨é€£æ¥æ± ç®¡ç†è³‡æ–™åº«é€£æ¥",
            "å¯¦æ–½é©ç•¶çš„å¿«å–ç­–ç•¥"
        ],
        "æ—¥èªŒå±¤é¢": [
            "é¸æ“‡é©ç•¶çš„æ—¥èªŒç´šåˆ¥",
            "ä½¿ç”¨éåŒæ­¥æ—¥èªŒå¯«å…¥",
            "åˆç†è¨­å®šæ—¥èªŒè¼ªæ›¿ç­–ç•¥",
            "é¿å…åœ¨é«˜é »è·¯å¾‘è¨˜éŒ„è©³ç´°æ—¥èªŒ"
        ],
        "ç›£æ§å±¤é¢": [
            "å»ºç«‹æ ¸å¿ƒæŒ‡æ¨™ç›£æ§",
            "è¨­å®šé©ç•¶çš„å‘Šè­¦é–¾å€¼",
            "å¯¦æ–½å¯¦æ™‚ç›£æ§å’Œå‘Šè­¦",
            "å®šæœŸåˆ†ææ€§èƒ½è¶¨å‹¢"
        ]
    }
    
    for category, tips in optimization_categories.items():
        logger.console_info(f"ğŸ“‹ {category}å„ªåŒ–å»ºè­°")
        logger.block(f"ğŸ’¡ {category}", tips, border_style="cyan")
        logger.info(f"æä¾› {category} å„ªåŒ–å»ºè­° - {len(tips)} é …")
        time.sleep(0.5)

def main():
    """ä¸»å‡½æ•¸"""
    print("=== Pretty Loguru æ€§èƒ½ç›£æ§å®Œæ•´æŒ‡å— ===")
    
    # 1. ç³»çµ±æ€§èƒ½ç›£æ§
    system_metrics = system_performance_monitor()
    
    # 2. æ‡‰ç”¨æ€§èƒ½ç›£æ§
    application_performance_monitor()
    
    # 3. è³‡æ–™åº«æ€§èƒ½ç›£æ§
    database_performance_monitor()
    
    # 4. å¯¦æ™‚ç›£æ§
    real_time_monitoring()
    
    # 5. æ€§èƒ½å„ªåŒ–å»ºè­°
    performance_optimization_tips()
    
    print("\n" + "="*50)
    print("æ€§èƒ½ç›£æ§æ¼”ç¤ºå®Œæˆ!")
    print("æª¢æŸ¥ä»¥ä¸‹ç›®éŒ„æŸ¥çœ‹æ€§èƒ½ç›£æ§æ—¥èªŒ:")
    print("- ./logs/performance/")
    print("\næ€§èƒ½ç›£æ§å¹«åŠ©æ‚¨:")
    print("â€¢ åŠæ—©ç™¼ç¾æ€§èƒ½ç“¶é ¸")
    print("â€¢ å„ªåŒ–ç³»çµ±è³‡æºä½¿ç”¨")
    print("â€¢ æå‡ç”¨æˆ¶é«”é©—")
    print("â€¢ é é˜²ç³»çµ±æ•…éšœ")

if __name__ == "__main__":
    main()