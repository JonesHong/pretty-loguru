# ğŸ’¼ 08_enterprise - ä¼æ¥­ç´šå ´æ™¯

æ­¡è¿ä¾†åˆ°ä¼æ¥­ç´šæ‡‰ç”¨å­¸ç¿’ï¼é€™å€‹æ¨¡çµ„å°ˆç‚ºå¤§è¦æ¨¡ç”Ÿç”¢ç’°å¢ƒè¨­è¨ˆï¼Œæ¶µè“‹å¾®æœå‹™æ¶æ§‹ã€å®‰å…¨åˆè¦ã€ç›£æ§æ•´åˆç­‰ä¼æ¥­ç´šéœ€æ±‚ã€‚

## ğŸ¯ å­¸ç¿’ç›®æ¨™

å®Œæˆæœ¬ç¯€å¾Œï¼Œæ‚¨å°‡ï¼š
- âœ… æŒæ¡å¾®æœå‹™æ—¥èªŒæ¶æ§‹è¨­è¨ˆ
- âœ… ç†è§£å®‰å…¨å’Œåˆè¦è¦æ±‚
- âœ… å­¸æœƒç›£æ§ç³»çµ±æ•´åˆ
- âœ… èƒ½å¤ è¨­è¨ˆä¼æ¥­ç´šæ—¥èªŒè§£æ±ºæ–¹æ¡ˆ

## ğŸ“š ç¯„ä¾‹åˆ—è¡¨ï¼ˆå»ºè­°é †åºï¼‰

### ğŸ—ï¸ Step 1: microservices_logging.py - å¾®æœå‹™æ—¥èªŒæ¶æ§‹
**â±ï¸ é ä¼°æ™‚é–“ï¼š30åˆ†é˜**

```bash
python microservices_logging.py
```

**å­¸ç¿’é‡é»**ï¼š
- åˆ†æ•£å¼æ—¥èªŒè¿½è¹¤
- æœå‹™é–“æ—¥èªŒé—œè¯
- çµ±ä¸€æ—¥èªŒæ ¼å¼æ¨™æº–
- æ—¥èªŒèšåˆç­–ç•¥

### ğŸ”’ Step 2: security_logging.py - å®‰å…¨ç›¸é—œæ—¥èªŒ
**â±ï¸ é ä¼°æ™‚é–“ï¼š25åˆ†é˜**

```bash
python security_logging.py
```

**å­¸ç¿’é‡é»**ï¼š
- å®‰å…¨äº‹ä»¶è¨˜éŒ„
- å¯©è¨ˆæ—¥èªŒè¦æ±‚
- æ•æ„Ÿè³‡è¨Šè™•ç†
- å…¥ä¾µæª¢æ¸¬æ—¥èªŒ

### ğŸ“‹ Step 3: compliance.py - åˆè¦æ€§è¦æ±‚
**â±ï¸ é ä¼°æ™‚é–“ï¼š20åˆ†é˜**

```bash
python compliance.py
```

**å­¸ç¿’é‡é»**ï¼š
- GDPR/CCPA åˆè¦
- æ—¥èªŒä¿ç•™æ”¿ç­–
- æ•¸æ“šåŒ¿ååŒ–
- åˆè¦å¯©è¨ˆæ”¯æ´

### ğŸ“Š Step 4: monitoring_integration.py - ç›£æ§ç³»çµ±æ•´åˆ
**â±ï¸ é ä¼°æ™‚é–“ï¼š35åˆ†é˜**

```bash
python monitoring_integration.py
```

**å­¸ç¿’é‡é»**ï¼š
- Prometheus æŒ‡æ¨™æ•´åˆ
- Grafana å„€è¡¨æ¿
- ELK Stack æ•´åˆ
- å ±è­¦å’Œé€šçŸ¥ç³»çµ±

## ğŸ® ä¼æ¥­ç’°å¢ƒæ¨¡æ“¬

```bash
# å•Ÿå‹•å¾®æœå‹™é›†ç¾¤æ¨¡æ“¬
docker-compose up -d

# é‹è¡Œä¼æ¥­ç´šç¯„ä¾‹
python microservices_logging.py &
python security_logging.py &
python compliance.py &
python monitoring_integration.py &

# ç”Ÿæˆä¼æ¥­ç´šè² è¼‰
./scripts/generate_enterprise_load.sh

# æª¢æŸ¥ä¼æ¥­ç´šç›£æ§
curl http://localhost:3000/metrics  # Prometheus æŒ‡æ¨™
curl http://localhost:9200/_search  # Elasticsearch æŸ¥è©¢
```

## ğŸ’¡ ä¼æ¥­ç´šæ¶æ§‹æ¨¡å¼

### åˆ†æ•£å¼è¿½è¹¤
```python
import uuid
from contextvars import ContextVar
from typing import Optional

# å…¨å±€è¿½è¹¤ä¸Šä¸‹æ–‡
trace_id_var: ContextVar[Optional[str]] = ContextVar('trace_id', default=None)
span_id_var: ContextVar[Optional[str]] = ContextVar('span_id', default=None)

class DistributedTracing:
    """åˆ†æ•£å¼è¿½è¹¤ç®¡ç†"""
    
    @staticmethod
    def start_trace() -> str:
        """é–‹å§‹æ–°çš„è¿½è¹¤"""
        trace_id = str(uuid.uuid4())
        trace_id_var.set(trace_id)
        return trace_id
    
    @staticmethod
    def start_span(operation: str) -> str:
        """é–‹å§‹æ–°çš„ span"""
        span_id = str(uuid.uuid4())
        span_id_var.set(span_id)
        
        logger.info(
            f"é–‹å§‹æ“ä½œ: {operation}",
            extra={
                "trace_id": trace_id_var.get(),
                "span_id": span_id,
                "operation": operation,
                "event_type": "span_start"
            }
        )
        return span_id
    
    @staticmethod
    def end_span(operation: str, status: str = "success"):
        """çµæŸ span"""
        logger.info(
            f"å®Œæˆæ“ä½œ: {operation}",
            extra={
                "trace_id": trace_id_var.get(),
                "span_id": span_id_var.get(),
                "operation": operation,
                "status": status,
                "event_type": "span_end"
            }
        )

# ä½¿ç”¨åˆ†æ•£å¼è¿½è¹¤
async def process_user_request(user_id: int):
    trace_id = DistributedTracing.start_trace()
    
    try:
        # ç”¨æˆ¶é©—è­‰æœå‹™
        DistributedTracing.start_span("user_authentication")
        await authenticate_user(user_id)
        DistributedTracing.end_span("user_authentication")
        
        # æ¥­å‹™é‚è¼¯æœå‹™
        DistributedTracing.start_span("business_logic")
        result = await process_business_logic(user_id)
        DistributedTracing.end_span("business_logic")
        
        # æ•¸æ“šæŒä¹…åŒ–æœå‹™
        DistributedTracing.start_span("data_persistence")
        await save_result(result)
        DistributedTracing.end_span("data_persistence")
        
    except Exception as e:
        logger.error(
            "è«‹æ±‚è™•ç†å¤±æ•—",
            extra={
                "trace_id": trace_id,
                "user_id": user_id,
                "error": str(e),
                "error_type": type(e).__name__
            }
        )
        raise
```

### å®‰å…¨æ—¥èªŒç®¡ç†
```python
import hashlib
from enum import Enum
from datetime import datetime, timedelta

class SecurityEventType(Enum):
    LOGIN_SUCCESS = "login_success"
    LOGIN_FAILURE = "login_failure"
    PRIVILEGE_ESCALATION = "privilege_escalation"
    DATA_ACCESS = "data_access"
    CONFIGURATION_CHANGE = "config_change"
    SUSPICIOUS_ACTIVITY = "suspicious_activity"

class SecurityLogger:
    """å®‰å…¨äº‹ä»¶å°ˆç”¨æ—¥èªŒè¨˜éŒ„å™¨"""
    
    def __init__(self):
        self.failed_attempts = {}
        self.logger = create_logger(
            "security",
            log_path="/var/log/security",
            level="INFO",
            rotation="daily",
            retention="7 years"  # åˆè¦è¦æ±‚
        )
    
    def log_security_event(
        self,
        event_type: SecurityEventType,
        user_id: str,
        ip_address: str,
        details: dict = None
    ):
        """è¨˜éŒ„å®‰å…¨äº‹ä»¶"""
        
        # åŒ¿ååŒ–ç”¨æˆ¶ IDï¼ˆåˆè¦è¦æ±‚ï¼‰
        anonymous_user_id = self._anonymize_user_id(user_id)
        
        security_log = {
            "event_type": event_type.value,
            "user_id": anonymous_user_id,
            "ip_address": self._anonymize_ip(ip_address),
            "timestamp": datetime.utcnow().isoformat(),
            "details": details or {},
            "severity": self._get_severity(event_type)
        }
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºå¯ç–‘æ´»å‹•
        if self._is_suspicious_activity(user_id, ip_address, event_type):
            security_log["alert"] = True
            self._trigger_security_alert(security_log)
        
        self.logger.info("å®‰å…¨äº‹ä»¶", extra=security_log)
    
    def _anonymize_user_id(self, user_id: str) -> str:
        """åŒ¿ååŒ–ç”¨æˆ¶ ID"""
        return hashlib.sha256(f"{user_id}:salt".encode()).hexdigest()[:16]
    
    def _anonymize_ip(self, ip_address: str) -> str:
        """åŒ¿ååŒ– IP åœ°å€"""
        parts = ip_address.split('.')
        return f"{parts[0]}.{parts[1]}.*.* "
    
    def _is_suspicious_activity(
        self,
        user_id: str,
        ip_address: str,
        event_type: SecurityEventType
    ) -> bool:
        """æª¢æ¸¬å¯ç–‘æ´»å‹•"""
        
        if event_type == SecurityEventType.LOGIN_FAILURE:
            # è¿½è¹¤å¤±æ•—å˜—è©¦
            key = f"{user_id}:{ip_address}"
            now = datetime.utcnow()
            
            if key not in self.failed_attempts:
                self.failed_attempts[key] = []
            
            # æ¸…ç†èˆŠè¨˜éŒ„
            self.failed_attempts[key] = [
                timestamp for timestamp in self.failed_attempts[key]
                if now - timestamp < timedelta(minutes=15)
            ]
            
            self.failed_attempts[key].append(now)
            
            # 15åˆ†é˜å…§è¶…é5æ¬¡å¤±æ•—å˜—è©¦
            return len(self.failed_attempts[key]) > 5
        
        return False
    
    def _trigger_security_alert(self, security_log: dict):
        """è§¸ç™¼å®‰å…¨è­¦å ±"""
        # æ•´åˆç›£æ§ç³»çµ±
        alert_manager.send_alert(
            severity="critical",
            message=f"å®‰å…¨äº‹ä»¶æª¢æ¸¬: {security_log['event_type']}",
            details=security_log
        )
```

### åˆè¦æ€§ç®¡ç†
```python
from datetime import datetime, timedelta
import json
from typing import List, Dict

class ComplianceManager:
    """åˆè¦æ€§ç®¡ç†å™¨"""
    
    def __init__(self):
        self.retention_policies = {
            "financial": timedelta(days=2555),  # 7 å¹´
            "personal_data": timedelta(days=365),  # 1 å¹´
            "system_logs": timedelta(days=90),   # 3 å€‹æœˆ
            "security_logs": timedelta(days=2555)  # 7 å¹´
        }
    
    def apply_data_retention(self, log_category: str):
        """æ‡‰ç”¨æ•¸æ“šä¿ç•™æ”¿ç­–"""
        if log_category in self.retention_policies:
            retention_period = self.retention_policies[log_category]
            cutoff_date = datetime.utcnow() - retention_period
            
            logger.info(
                "æ‡‰ç”¨æ•¸æ“šä¿ç•™æ”¿ç­–",
                extra={
                    "category": log_category,
                    "retention_period_days": retention_period.days,
                    "cutoff_date": cutoff_date.isoformat(),
                    "compliance_action": "data_retention"
                }
            )
    
    def anonymize_personal_data(self, log_record: dict) -> dict:
        """åŒ¿ååŒ–å€‹äººæ•¸æ“š"""
        personal_fields = [
            'email', 'phone', 'address', 'name',
            'ssn', 'passport', 'credit_card'
        ]
        
        for field in personal_fields:
            if field in log_record:
                log_record[field] = self._anonymize_field(
                    log_record[field], field
                )
        
        log_record['_anonymized'] = True
        log_record['_anonymization_date'] = datetime.utcnow().isoformat()
        
        return log_record
    
    def generate_compliance_report(self) -> Dict:
        """ç”Ÿæˆåˆè¦å ±å‘Š"""
        report = {
            "report_date": datetime.utcnow().isoformat(),
            "compliance_framework": ["GDPR", "CCPA", "SOX"],
            "data_categories": list(self.retention_policies.keys()),
            "retention_policies": {
                k: v.days for k, v in self.retention_policies.items()
            },
            "anonymization_status": "active",
            "audit_trail": "enabled"
        }
        
        logger.info("åˆè¦å ±å‘Šç”Ÿæˆ", extra=report)
        return report
```

### ç›£æ§ç³»çµ±æ•´åˆ
```python
from prometheus_client import Counter, Histogram, Gauge
import json
import time

class MonitoringIntegration:
    """ç›£æ§ç³»çµ±æ•´åˆ"""
    
    def __init__(self):
        # Prometheus æŒ‡æ¨™
        self.log_counter = Counter(
            'logs_total',
            'Total number of logs',
            ['level', 'service']
        )
        
        self.log_processing_time = Histogram(
            'log_processing_seconds',
            'Time spent processing logs'
        )
        
        self.active_connections = Gauge(
            'active_connections',
            'Number of active connections'
        )
    
    def track_log_metrics(self, level: str, service: str):
        """è¿½è¹¤æ—¥èªŒæŒ‡æ¨™"""
        self.log_counter.labels(level=level, service=service).inc()
    
    def track_processing_time(self, duration: float):
        """è¿½è¹¤è™•ç†æ™‚é–“"""
        self.log_processing_time.observe(duration)
    
    def send_to_elasticsearch(self, log_record: dict):
        """ç™¼é€åˆ° Elasticsearch"""
        try:
            start_time = time.time()
            
            # æ ¼å¼åŒ–ç‚º ELK æ ¼å¼
            elk_record = {
                "@timestamp": datetime.utcnow().isoformat(),
                "@version": "1",
                "host": "localhost",
                "message": log_record.get("message", ""),
                "level": log_record.get("level", "INFO"),
                "logger": log_record.get("logger", "default"),
                "thread": log_record.get("thread", "main"),
                "fields": log_record.get("extra", {})
            }
            
            # ç™¼é€åˆ° Elasticsearch
            # elasticsearch_client.index(
            #     index=f"logs-{datetime.utcnow().strftime('%Y-%m-%d')}",
            #     body=elk_record
            # )
            
            processing_time = time.time() - start_time
            self.track_processing_time(processing_time)
            
        except Exception as e:
            logger.error(f"Elasticsearch ç™¼é€å¤±æ•—: {e}")
    
    def setup_grafana_dashboard(self):
        """è¨­ç½® Grafana å„€è¡¨æ¿"""
        dashboard_config = {
            "dashboard": {
                "title": "Pretty-Loguru Monitoring",
                "panels": [
                    {
                        "title": "Log Volume",
                        "type": "graph",
                        "targets": [
                            {
                                "expr": "rate(logs_total[5m])",
                                "legendFormat": "{{level}} - {{service}}"
                            }
                        ]
                    },
                    {
                        "title": "Processing Time",
                        "type": "graph", 
                        "targets": [
                            {
                                "expr": "histogram_quantile(0.95, log_processing_seconds)",
                                "legendFormat": "95th percentile"
                            }
                        ]
                    }
                ]
            }
        }
        
        logger.info("Grafana å„€è¡¨æ¿é…ç½®", extra=dashboard_config)
```

## ğŸ—ï¸ ä¼æ¥­ç´šéƒ¨ç½²æ¶æ§‹

### Docker Compose ç¯„ä¾‹
```yaml
version: '3.8'
services:
  app:
    build: .
    environment:
      - LOG_LEVEL=INFO
      - LOG_PATH=/var/log/app
      - ELASTICSEARCH_URL=http://elasticsearch:9200
    volumes:
      - ./logs:/var/log/app
    depends_on:
      - elasticsearch
      - prometheus
  
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.14.0
    environment:
      - discovery.type=single-node
    ports:
      - "9200:9200"
  
  prometheus:
    image: prom/prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
  
  grafana:
    image: grafana/grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
```

## â¡ï¸ å¯¦æ–½æŒ‡å—

### éšæ®µæ€§éƒ¨ç½²
1. **ç¬¬ä¸€éšæ®µ**ï¼šåŸºç¤æ¶æ§‹å»ºç«‹ï¼ˆ1-2é€±ï¼‰
2. **ç¬¬äºŒéšæ®µ**ï¼šå®‰å…¨å’Œåˆè¦å¯¦æ–½ï¼ˆ2-3é€±ï¼‰
3. **ç¬¬ä¸‰éšæ®µ**ï¼šç›£æ§å’Œå ±è­¦æ•´åˆï¼ˆ1-2é€±ï¼‰
4. **ç¬¬å››éšæ®µ**ï¼šå„ªåŒ–å’Œèª¿å„ªï¼ˆæŒçºŒé€²è¡Œï¼‰

### åœ˜éšŠåŸ¹è¨“
- ğŸ“ [ä¼æ¥­ç´šæ—¥èªŒæœ€ä½³å¯¦è¸åŸ¹è¨“](../../docs/training/enterprise.md)
- ğŸ“š [é‹ç¶­åœ˜éšŠæ“ä½œæ‰‹å†Š](../../docs/operations/manual.md)
- ğŸ”§ [æ•…éšœæ’é™¤æŒ‡å—](../../docs/troubleshooting/enterprise.md)

---

**ğŸ’¼ æ§‹å»ºä¼æ¥­ç´šçš„æ—¥èªŒåŸºç¤è¨­æ–½ï¼**

å®Œå–„çš„ä¼æ¥­ç´šæ—¥èªŒç³»çµ±æ˜¯ç¾ä»£åŒ– IT åŸºç¤è¨­æ–½çš„æ ¸å¿ƒçµ„ä»¶ã€‚